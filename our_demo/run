import os
import re
import streamlit as st
from dotenv import load_dotenv
from langchain_upstage import ChatUpstage
import plotly.graph_objects as go
from textblob import TextBlob

# Load environment variables
load_dotenv()

# Get Upstage API Key
UPSTAGE_API_KEY = os.getenv("UPSTAGE_API_KEY")

# Check if API key is available
if not UPSTAGE_API_KEY:
    st.error("UPSTAGE_API_KEY is not set in the environment variables.")
    st.stop()

# Initialize Upstage Chat model
chat = ChatUpstage(upstage_api_key=UPSTAGE_API_KEY)

# Prompt file path
DETECTION_PROMPT_FILE = "/mnt/c/Users/kec91/Desktop/KuUpstage/phase1/demo_eunche/detection_prompt.txt"

# Read prompt from file
def load_detection_prompt():
    try:
        with open(DETECTION_PROMPT_FILE, 'r', encoding='utf-8') as file:
            prompt_template = file.read()
        return prompt_template
    except FileNotFoundError:
        st.error(f"{DETECTION_PROMPT_FILE} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

# Calculate GPT generation probability
def calculate_gpt_probability(text):
    score = 0
    total_checks = 4

    if len(text) > 100:
        score += 1
    complex_words = ['therefore', 'furthermore', 'consequently', 'nevertheless']
    if any(word in text.lower() for word in complex_words):
        score += 1
    sentences = re.split(r'[.!?]+', text)
    if len(set([len(s.split()) for s in sentences if s])) > 2:
        score += 1
    if re.search(r'\d+\s*(kg|km|m|cm)', text):
        score += 1

    return (score / total_checks) * 100

# Text detection and AI response processing function
def upstage_text_detection_with_prompt(user_input):
    prompt_template = load_detection_prompt()
    
    if prompt_template is None:
        return "í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", None

    prompt = prompt_template.format(input_text=user_input)
    response = chat([{"role": "user", "content": prompt}])

    try:
        full_response = response.content
        probability = calculate_gpt_probability(user_input)
    except AttributeError:
        full_response = "ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        probability = None

    return full_response, probability

# Create radar chart
def create_radar_chart(probability):
    categories = ['Length', 'Complexity', 'Structure', 'Patterns']
    fig = go.Figure(data=go.Scatterpolar(
      r=[probability/100*4] * 4,
      theta=categories,
      fill='toself'
    ))
    fig.update_layout(
      polar=dict(radialaxis=dict(visible=True, range=[0, 4])),
      showlegend=False
    )
    return fig

# Streamlit UI
def main_app():
    st.set_page_config(page_title="GPT ê°ì§€ ëŒ€ì‹œë³´ë“œ", layout="wide")

    # Initialize session state for history
    if 'history' not in st.session_state:
        st.session_state.history = []

    # Sidebar for session history
    st.sidebar.title("ì„¸ì…˜ íˆìŠ¤í† ë¦¬")
    for idx, item in enumerate(st.session_state.history):
        if st.sidebar.button(f"#{idx+1}: {item['input'][:20]}...", key=f"history_{idx}"):
            st.session_state.selected_history = item

    st.title("ğŸ•µï¸â€â™‚ï¸ GPT ê°ì§€ ë° ë¶„ì„ ëŒ€ì‹œë³´ë“œ")

    # Input area
    user_input = st.text_area("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", placeholder="ì—¬ê¸°ì— ë¶„ì„í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”...", height=100)

    if st.button("ğŸ” GPT ê°ì§€ ë° ë¶„ì„ ì‹œì‘"):
        if user_input:
            with st.spinner('ë¶„ì„ ì¤‘...'):
                detection_result, probability = upstage_text_detection_with_prompt(user_input)
            
            # Add to history
            st.session_state.history.append({
                'input': user_input,
                'result': detection_result,
                'probability': probability
            })
            st.session_state.selected_history = st.session_state.history[-1]

    # Display selected history or latest result
    if hasattr(st.session_state, 'selected_history'):
        selected = st.session_state.selected_history
        st.subheader("ğŸ“Š ë¶„ì„ ê²°ê³¼")
        st.write(selected['result'])

        if selected['probability'] is not None:
            st.metric(label="GPT ìƒì„± ê°€ëŠ¥ì„±", value=f"{selected['probability']:.2f}%")
        else:
            st.error("í™•ë¥  ì •ë³´ë¥¼ ê³„ì‚°í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        col1, col2 = st.columns([1, 1])

        with col1:
            st.subheader("ğŸ“ˆ ìƒì„¸ ë¶„ì„")
            fig = create_radar_chart(selected['probability'])
            st.plotly_chart(fig, use_container_width=True)

        with col2:
            st.subheader("ğŸ“ í…ìŠ¤íŠ¸ í†µê³„")
            word_count = len(selected['input'].split())
            char_count = len(selected['input'])
            sentence_count = len(re.findall(r'\w+[.!?]', selected['input']))
            
            st.write(f"ë‹¨ì–´ ìˆ˜: {word_count}")
            st.write(f"ë¬¸ì ìˆ˜: {char_count}")
            st.write(f"ë¬¸ì¥ ìˆ˜: {sentence_count}")

            blob = TextBlob(selected['input'])
            sentiment = blob.sentiment.polarity
            subjectivity = blob.sentiment.subjectivity

            st.subheader("ğŸ­ ê°ì • ë¶„ì„")
            st.write(f"ê°ì • ì ìˆ˜: {sentiment:.2f} (-1 ë¶€ì •ì , 1 ê¸ì •ì )")
            st.write(f"ì£¼ê´€ì„± ì ìˆ˜: {subjectivity:.2f} (0 ê°ê´€ì , 1 ì£¼ê´€ì )")

if __name__ == "__main__":
    main_app()
