import os
import re
import streamlit as st
from dotenv import load_dotenv
from langchain_upstage import ChatUpstage
import plotly.graph_objects as go
from collections import Counter
from PIL import Image
import base64
from io import BytesIO
from langchain.schema import HumanMessage

# Load environment variables
load_dotenv()

# Get Upstage API Key
UPSTAGE_API_KEY = os.getenv("UPSTAGE_API_KEY")

# Check if API key is available
if not UPSTAGE_API_KEY:
    st.error("UPSTAGE_API_KEY is not set in the environment variables.")
    st.stop()

# Initialize Upstage Chat model
try:
    chat = ChatUpstage(upstage_api_key=UPSTAGE_API_KEY)
except Exception as e:
    st.error(f"Failed to initialize ChatUpstage: {str(e)}")
    st.stop()

# Korean sentence tokenization function
def korean_sentence_tokenize(text):
    pattern = r'(?<=[.!?])\s+|(?<=[.!?])$'
    sentences = re.split(pattern, text)
    return [sent.strip() for sent in sentences if sent.strip()]

# Prompt file path
DETECTION_PROMPT_FILE = "/mnt/c/Users/kec91/Desktop/KuUpstage/phase1/our_demo/detection_prompt.txt"

# Read prompt from file
def load_detection_prompt():
    try:
        with open(DETECTION_PROMPT_FILE, 'r', encoding='utf-8') as file:
            prompt_template = file.read()
        return prompt_template
    except FileNotFoundError:
        st.error(f"{DETECTION_PROMPT_FILE} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    except Exception as e:
        st.error(f"í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None


# íŒŒì¼ì—ì„œ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ë¥¼ ì½ì–´ì˜¤ëŠ” í•¨ìˆ˜
def read_word_list(file_path):
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            return [word.strip() for word in file.readlines() if word.strip()]
    except FileNotFoundError:
        st.error(f"{file_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []
    except Exception as e:
        st.error(f"íŒŒì¼ ì½ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return []

# íŒŒì¼ ê²½ë¡œ ì„¤ì • (ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ ìˆ˜ì • í•„ìš”)
ADVERB_FILE = "/mnt/c/Users/kec91/Desktop/KuUpstage/phase1/our_demo/textmining/adverb_list.txt"
NOUN_FILE = "/mnt/c/Users/kec91/Desktop/KuUpstage/phase1/our_demo/textmining/noun_list.txt"
VERB_FILE = "/mnt/c/Users/kec91/Desktop/KuUpstage/phase1/our_demo/textmining/verb_list.txt"
ADJECTIVE_FILE = "/mnt/c/Users/kec91/Desktop/KuUpstage/phase1/our_demo/textmining/adjective_list.txt"

# ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ ë¡œë“œ
ADVERBS = read_word_list(ADVERB_FILE)
NOUNS = read_word_list(NOUN_FILE)
VERBS = read_word_list(VERB_FILE)
ADJECTIVES = read_word_list(ADJECTIVE_FILE)


def calculate_korean_gpt_probability(text):
    score = 0
    total_checks = 100  # ì²´í¬ í•­ëª© ìˆ˜
    text_length = len(text)

    # í…ìŠ¤íŠ¸ ê¸¸ì´ì— ë”°ë¥¸ ê¸°ì¤€ ì„¤ì •
    # length_threshold = 500  # 500ìë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì„¤ì •
    # length_factor = min(text_length / length_threshold, 1)  # 1ì„ ì´ˆê³¼í•˜ì§€ ì•Šë„ë¡ ì œí•œ

    # ì‰¼í‘œ ê°œìˆ˜ ì²´í¬ (ìˆ˜ì •ëœ ë¶€ë¶„)
    sentences = re.split(r'[.!?]+', text)
    sentences = [s.strip() for s in sentences if s.strip()]  # ë¹ˆ ë¬¸ì¥ ì œê±°
    sentences_with_many_commas = [s for s in sentences if s.count(',') >= 2]
    if len(sentences_with_many_commas) >= 1:  # 10% ì´ìƒì˜ ë¬¸ì¥ì´ ì‰¼í‘œ 2ê°œ ì´ìƒì´ë©´
        score += 20

    # ìì£¼ ë“±ì¥í•˜ëŠ” ë¶€ë¶„ ì²´í¬
    korean_connectives = ['ì‹œì ˆ', 'ë§¡ì•˜ìœ¼ë©°', 'íŠ¹íˆ', 'ìš°ì„ ', 'ì…ì‚¬ í›„', 'ì—ì„œ,', 'ì´ì— ë”°ë¼', 'ë°”íƒ•ìœ¼ë¡œ', 'ì €ëŠ”', 'ê³ ,', 'ì´ëŠ”', 'í†µí•´']
    connective_count = sum(text.count(word) for word in korean_connectives)
    if connective_count >= 2 :#* length_factor:  # í…ìŠ¤íŠ¸ ê¸¸ì´ì— ë¹„ë¡€í•˜ì—¬ ì¡°ì •
        score += 35

    # ê¸´ ë¬¸ì¥ ì²´í¬
    if sentences:
        long_sentences = [s for s in sentences if len(s.split()) > 20]
        if len(long_sentences) >= len(sentences) * 0.3 :#* length_factor / 2:  # í…ìŠ¤íŠ¸ ê¸¸ì´ì— ë¹„ë¡€í•˜ì—¬ ì¡°ì •
            score += 15

    # ë¶€ì‚¬ ì‚¬ìš© ì²´í¬
    adverb_count = sum(text.count(adverb) for adverb in ADVERBS)
    if adverb_count >= 2 :# * length_factor:  # í…ìŠ¤íŠ¸ ê¸¸ì´ì— ë¹„ë¡€í•˜ì—¬ ì¡°ì •
        score += 15

    # ëª…ì‚¬ ì‚¬ìš© ì²´í¬
    noun_count = sum(text.count(noun) for noun in NOUNS)
    if noun_count >= 2 :# * length_factor:  # í…ìŠ¤íŠ¸ ê¸¸ì´ì— ë¹„ë¡€í•˜ì—¬ ì¡°ì •
        score += 5

    # ë™ì‚¬ ì‚¬ìš© ì²´í¬
    verb_count = sum(text.count(verb) for verb in VERBS)
    if verb_count >= 2 :#* length_factor:  # í…ìŠ¤íŠ¸ ê¸¸ì´ì— ë¹„ë¡€í•˜ì—¬ ì¡°ì •
        score += 5

    # í˜•ìš©ì‚¬ ì‚¬ìš© ì²´í¬
    adj_count = sum(text.count(adj) for adj in ADJECTIVES)
    if adj_count >= 2 :# * length_factor:  # í…ìŠ¤íŠ¸ ê¸¸ì´ì— ë¹„ë¡€í•˜ì—¬ ì¡°ì •
        score += 5
    

    # í…ìŠ¤íŠ¸ ê¸¸ì´ì— ë”°ë¥¸ ì ìˆ˜ ì¡°ì •
    # normalized_score = score * (1 - 0.2 * length_factor)  # í…ìŠ¤íŠ¸ê°€ ê¸¸ìˆ˜ë¡ ì ìˆ˜ë¥¼ ì•½ê°„ ë‚®ì¶¤

    return (score / total_checks) * 100

# í…ìŠ¤íŠ¸ì—ì„œ GPT ì‚¬ìš© ê°€ëŠ¥ì„±ì´ ë†’ì€ ë¬¸ì¥ ì‹ë³„ í•¨ìˆ˜
def identify_gpt_sentences(text, threshold=50):
    sentences = korean_sentence_tokenize(text)
    gpt_sentences = []
    for sentence in sentences:
        probability = calculate_korean_gpt_probability(sentence)
        if probability >= threshold:
            gpt_sentences.append((sentence, probability))
    return gpt_sentences

# í•˜ì´ë¼ì´íŠ¸ëœ í…ìŠ¤íŠ¸ ìƒì„± í•¨ìˆ˜
def create_highlighted_text(text, gpt_sentences):
    highlighted_text = text
    for sentence, probability in sorted(gpt_sentences, key=lambda x: len(x[0]), reverse=True):
        highlighted_sentence = f'<span style="background-color: rgba(128, 92, 251, {probability/100});">{sentence}</span>'
        highlighted_text = highlighted_text.replace(sentence, highlighted_sentence)
    return highlighted_text

# Text detection and AI response processing function
def upstage_text_detection_with_prompt(user_input):
    prompt_template = load_detection_prompt()

    if prompt_template is None:
        return "í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", None

    # Calculate GPT probability for user input
    probability = calculate_korean_gpt_probability(user_input)

    # Modify prompt to include the user's input and their question
    prompt = prompt_template.format(input_text=user_input, probability_score=probability)

    try:
        response = chat.invoke([HumanMessage(content=prompt)])
        full_response = response.content
    except Exception as e:
        full_response = f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        probability = None

    return full_response, probability

# ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ì¸ì½”ë”©í•˜ëŠ” í•¨ìˆ˜
def image_to_base64(image):
    buffered = BytesIO()
    image.save(buffered, format="PNG")
    img_str = base64.b64encode(buffered.getvalue()).decode()
    return img_str

def create_gauge_chart(probability):
    base_color = "#805CFB"
    grape_color = "rgba(255, 255, 255, 0.8)"
    lighter_color = "#A389FD"
    darker_color = "#5C3DB8"

    fig = go.Figure(go.Indicator(
        mode="gauge+number",
        value=probability,
        title={'text': "GPT ìƒì„± ê°€ëŠ¥ì„±", 'font': {'size': 24}},
        domain={'x': [0, 1], 'y': [0, 1]},
        number={'font': {'size': 40}, 'suffix': "%"},
        gauge={
            'axis': {'range': [None, 100], 'tickwidth': 1, 'tickcolor': "darkblue"},
            'bar': {'color': grape_color},
            'bgcolor': "white",
            'borderwidth': 0.8,
            'bordercolor': "gray",
            'steps': [
                {'range': [0, 33], 'color': darker_color},
                {'range': [33, 66], 'color': base_color},
                {'range': [66, 100], 'color': lighter_color}
            ],
            'threshold': {
                'line': {'color': "red", 'width': 4},
                'thickness': 0.60,
                'value': 70
            }
        }))
    fig.update_layout(height=300, margin=dict(l=10, r=10, t=40, b=10))
    return fig

# í‚¤ì›Œë“œ ë¶„ì„ í•¨ìˆ˜
def analyze_keywords(text):
    words = re.findall(r'\w+', text.lower())
    word_freq = Counter(words)
    return word_freq.most_common(5)  # ìƒìœ„ 5ê°œ í‚¤ì›Œë“œ ë°˜í™˜

# í‚¤ì›Œë“œ ê·¸ë˜í”„ ìƒì„± í•¨ìˆ˜
def create_keyword_chart(keywords):
    words, counts = zip(*keywords)
    base_color = "#805CFB"
    color_scale = [
        f"rgba({128 + i * 25}, {92 + i * 25}, {251}, {1 - i * 0.15})"
        for i in range(5)
    ]

    fig = go.Figure(data=[
        go.Bar(x=counts, y=words, orientation='h', 
               marker_color=color_scale)
    ])

    fig.update_layout(
        title="ì£¼ìš” í‚¤ì›Œë“œ",
        xaxis_title="ì¶œí˜„ ë¹ˆë„",
        yaxis_title="í‚¤ì›Œë“œ",
        height=300,
        plot_bgcolor='rgba(0,0,0,0)',
        paper_bgcolor='rgba(0,0,0,0)'
    )
    fig.update_yaxes(autorange="reversed")

    return fig

# Streamlit UI
def main_app():
    st.set_page_config(page_title="GPT ê°ì§€ ë³´ê³ ì„œ", layout="wide")

    # ì‚¬ì´ë“œë°” ì»¨í…ì¸ 
    with st.sidebar:
        st.markdown("""
        ğŸ“ **ì•Œë¦¼**    
        í•´ë‹¹ í˜ì´ì§€ëŠ” ê³ ë ¤ëŒ€í•™êµì™€ upstageê°€ í•¨ê»˜í•˜ëŠ” ëª…í’ˆì¸ì¬ í”„ë¡œì íŠ¸ ì¶œì „ì‘ ì…ë‹ˆë‹¤.  
        """)
        st.subheader("ğŸ§‘â€ğŸ’» ë§Œë“ ì´")
        st.markdown("""
        ê³ ë ¤ëŒ€í•™êµ BAê³¼ì • ê¹€ì€ì±„, ì´ìê²½, ì§€í˜„ì•„
        """)
        
        # ë§¨ ì•„ë˜ì— ë¡œê³  ì¶”ê°€ë¥¼ ìœ„í•œ ê³µê°„ í™•ë³´
        st.markdown("<div style='flex-grow: 1; height: 600px;'></div>", unsafe_allow_html=True)
        
        st.markdown("---")
    
        # í•™êµ ë¡œê³  ë¶ˆëŸ¬ì˜¤ê¸°
        school_logo = Image.open("/mnt/c/Users/kec91/Desktop/KuUpstage/phase1/our_demo/static/korea_univ.png")
        company_logo = Image.open("/mnt/c/Users/kec91/Desktop/KuUpstage/phase1/our_demo/static/upstage.png")
        
        # ë¡œê³ ë¥¼ Base64ë¡œ ì¸ì½”ë”©í•œ í›„ HTMLë¡œ ì‚½ì…
        school_logo_base64 = image_to_base64(school_logo)
        company_logo_base64 = image_to_base64(company_logo)
        
        # í•˜ë‹¨ì— ë¡œê³ ì™€ ì¹´í”¼ë¼ì´íŠ¸ ë°°ì¹˜ (ì—¬ìœ  ê³µê°„ì„ í™•ë³´í•œ í›„ ë°°ì¹˜)
        st.markdown(f"""
        <div style="text-align: center; margin-top: 50px;">
            <img src="data:image/png;base64,{school_logo_base64}" width="200"/>
            <img src="data:image/png;base64,{company_logo_base64}" width="200"/>
            <p>Â© 2024 ê³ ë ¤ëŒ€í•™êµ & KU-Upstage. All rights reserved.</p>
        </div>
        """, unsafe_allow_html=True)
    
    # ë©”ì¸ ì»¨í…ì¸ 
    st.title("ğŸ•µï¸â€â™‚ï¸ GPT ê°ì§€ ë° ë¶„ì„ ë³´ê³ ì„œ")

    # ì…ë ¥ ì„¹ì…˜
    st.header("ìê¸°ì†Œê°œì„œ í™•ì¸í•´ë³´ê¸°")
    user_input = st.text_area("ë¶„ì„í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", placeholder="ì—¬ê¸°ì— í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”...", height=300)



    analyze_button = st.button("ğŸ” GPT ê°ì§€ ë° ë¶„ì„ ì‹œì‘")

    if analyze_button and user_input:  # ì—¬ê¸°ì„œ user_inputì„ ì²´í¬í•©ë‹ˆë‹¤.
        with st.spinner('ë¶„ì„ ì¤‘...'):
            detection_result, probability = upstage_text_detection_with_prompt(user_input)
            gpt_sentences = identify_gpt_sentences(user_input, threshold=0)

        # ë¶„ì„ ê²°ê³¼ ì„¹ì…˜
        st.header("ë¶„ì„ ê²°ê³¼")
        st.subheader("GPT ê°ì§€ ê²°ê³¼")
        st.info(detection_result)

        if probability is not None:
            st.subheader("GPT ìƒì„± ê°€ëŠ¥ì„±")
            fig = create_gauge_chart(probability)
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.error("í™•ë¥  ì •ë³´ë¥¼ ê³„ì‚°í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        # GPT ì‚¬ìš© ê°€ëŠ¥ì„±ì´ ë†’ì€ ë¬¸ì¥ í•˜ì´ë¼ì´íŠ¸
        if gpt_sentences:
            st.subheader("GPT ì‚¬ìš© ê°€ëŠ¥ì„±ì´ ë†’ì€ ë¶€ë¶„")
            highlighted_text = create_highlighted_text(user_input, gpt_sentences)
            st.markdown(highlighted_text, unsafe_allow_html=True)

            # GPT ì‚¬ìš© ê°€ëŠ¥ì„±ì´ ë†’ì€ ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸
            st.subheader("GPT ì‚¬ìš© ê°€ëŠ¥ì„±ì´ ë†’ì€ ë¬¸ì¥")
            for sentence, prob in gpt_sentences:
                st.markdown(f"- {sentence} (í™•ë¥ : {prob:.2f}%)")
        else:
            st.info("GPT ì‚¬ìš© ê°€ëŠ¥ì„±ì´ ë†’ì€ ë¬¸ì¥ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # í…ìŠ¤íŠ¸ í†µê³„ ì„¹ì…˜
        st.header("í…ìŠ¤íŠ¸ í†µê³„")
        col1, col2, col3 = st.columns(3)
        word_count = len(user_input.split())
        char_count = len(user_input)
        sentence_count = len(re.findall(r'\w+[.!?]', user_input))
        
        with col1:
            st.metric("ë‹¨ì–´ ìˆ˜", word_count)
        with col2:
            st.metric("ë¬¸ì ìˆ˜", char_count)
        with col3:
            st.metric("ë¬¸ì¥ ìˆ˜", sentence_count)

        # í‚¤ì›Œë“œ ë¶„ì„ ì„¹ì…˜
        st.header("ì£¼ìš” í‚¤ì›Œë“œ ë¶„ì„")
        keywords = analyze_keywords(user_input)
        fig = create_keyword_chart(keywords)
        st.plotly_chart(fig, use_container_width=True)

if __name__ == "__main__":
    main_app()
